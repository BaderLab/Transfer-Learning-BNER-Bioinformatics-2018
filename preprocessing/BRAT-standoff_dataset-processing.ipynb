{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRAT-Standoff Dataset Proccessing\n",
    "\n",
    "_Motivation_: The purpose of this notebook is to facilitate data cleaning, exploration and visulization of corpora in the biomedical domain.\n",
    "\n",
    "_Prerequisites_: corpora must be in the BRAT-Standoff annotation (also known as A1).\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Data Cleaning](#Data-Cleaning)\n",
    "2. [Corpus Processing](#Corpus-Processing)\n",
    "3. [Corpus Statistics](#Corpus-Statistics) \n",
    "4. [Harmonize SSC with multiple GSC](#Harmonize-SSC-with-multiple-GSC)\n",
    "    - [Extract disjunction of annotated entity sets](#Extract-disjunction-of-annotated-entity-sets)\n",
    "5. [Evaluating a model](#Evaluating-a-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the following cell to install all requirements. _Note: its best to launch this notebook from a virtual enviornment_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install -U nltk sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code is stored in a single python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport brat_standoff_corpus_proccessing\n",
    "\n",
    "from brat_standoff_corpus_proccessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to set the path to all datasets you are working with as constants in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it is useful to set paths to different corpra here\n",
    "\n",
    "## SSC\n",
    "PATH_TO_CALBC_PRGE = ''\n",
    "PATH_TO_CALBC_LIVB = ''\n",
    "PATH_TO_CALBC_CHED = ''\n",
    "PATH_TO_CALBC_DISO = ''\n",
    "\n",
    "## GSC\n",
    "# CHED\n",
    "PATH_TO_CEMP = ''\n",
    "PATH_TO_CDR_CHED = ''\n",
    "PATH_TO_BIOSEMANTICS = ''\n",
    "PATH_TO_SCAI = ''\n",
    "# DISO\n",
    "PATH_TO_CDR_DISO = ''\n",
    "PATH_TO_MIRNA_DISO = ''\n",
    "PATH_TO_NCBI_DISEASE = ''\n",
    "PATH_TO_AZDC = ''\n",
    "# LIVB\n",
    "PATH_TO_S800 = ''\n",
    "PATH_TO_LINNAEUS = ''\n",
    "PATH_TO_MIRNA_LIVB = ''\n",
    "PATH_TO_CELLFINDER_LIVB = ''\n",
    "# PRGE\n",
    "PATH_TO_BIOINFER = ''\n",
    "PATH_TO_DECA = ''\n",
    "PATH_TO_MIRNA_PRGE = ''\n",
    "PATH_TO_FSU_PRGE = ''\n",
    "PATH_TO_CELLFINDER_PRGE = ''\n",
    "PATH_TO_IEPA = ''\n",
    "PATH_TO_OSIRIS = ''\n",
    "\n",
    "PATH_TO_PRGE_CORPORA = [PATH_TO_BIOINFER, PATH_TO_DECA, PATH_TO_MIRNA_PRGE, PATH_TO_FSU_PRGE, PATH_TO_CELLFINDER_PRGE]\n",
    "PATH_TO_LIVB_CORPORA = [PATH_TO_S800, PATH_TO_LINNAEUS, PATH_TO_MIRNA_LIVB, PATH_TO_CELLFINDER_LIVB]\n",
    "PATH_TO_CHED_CORPORA = [PATH_TO_CEMP, PATH_TO_CDR_CHED, PATH_TO_BIOSEMANTICS]\n",
    "PATH_TO_DISO_CORPORA = [PATH_TO_MIRNA_DISO, PATH_TO_CDR_DISO, PATH_TO_NCBI_DISEASE]\n",
    "\n",
    "CALBC_CHED_BLACKLIST = ''\n",
    "CALBC_PRGE_BLACKLIST = ''\n",
    "CALBC_LIVB_BLACKLIST = ''\n",
    "CALBC_DISO_BLACKLIST = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "This collection of methods performs various cleaning tasks on a corpora. Examples of their use is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__General cleaning tasks__: Remove hidden files, lone pairs, and invalid annotation pairs from a given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set path to corpus to clean here\n",
    "corpus_dir = PATH_TO_LINNAEUS\n",
    "\n",
    "rm_hidden_files(corpus_dir)\n",
    "rm_lone_pairs(corpus_dir)\n",
    "_ = rm_invalid_ann(corpus_dir, remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following function if you need to change the entity labels for a given entity in a given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change_ann_labels(corpus_dir, new_label='PRGE', labels_to_replace=['gene'], drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once data is cleaned, it's best to compress it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compress <directory> to <directory>.tar.gz\n",
    "# --------------------------------------\n",
    "# ! tar -zcvf <directory>.tar.gz <directory>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Processing\n",
    "\n",
    "A collection of functions for various corpus processing tasks. Examples of their use is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`extract_ann` is a simple function which extracts all unique entities in a corpus and returns a counter object. It is mainly used for downstream corpus processing tasks. Here is an example where it is used to print the top N most common entities in a corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_dir = PATH_TO_BIOINFER\n",
    "\n",
    "annotations = extract_ann(corpus_dir)\n",
    "print_top_bottom_n(annotations, n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_entity_in_corpra` is used to get a list of documents where a given entity exists in a corpus. Function allows for searching through either annotation and text files, or strictly annotation files (thus, the latter is equivant to checking if an annotation exists in a corpus). _Example usage_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_entity_in_corpra(PATH_TO_CALBC_LIVB, 'Respondents', search_text = False)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split_brat_standoff` randomly splits a corpus into disjoint train, test, and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set path to corpus to clean\n",
    "corpus_dir = PATH_TO_AZDC\n",
    "\n",
    "# set train, test and valid partition sizes\n",
    "TRAIN_SIZE = 0.6\n",
    "TEST_SIZE = 0.3\n",
    "VALID_SIZE = 0.1\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_brat_standoff(corpus_dir, TRAIN_SIZE, TEST_SIZE, VALID_SIZE, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Corpus Statistics \n",
    "\n",
    "Get corpus stats, including number of sentences, tokens, and annotations for a given corpus. Uses `NTLK` in order to perform word tokenization and sentence tokenization. _Example usage_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example use\n",
    "corpus_dir = PATH_TO_SCAI\n",
    "\n",
    "get_corpus_stats(corpus_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonize SSC with multiple GSC\n",
    "\n",
    "A collection of functions which facilitate the 'harmonization' of a SSC with multiple GSC. Examples of their use is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided a list of GSC, removes any document from a given SSC that appears in at least one of the GSC. _Example usage_: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GSC = [PATH_TO_AZDC] # a list containing paths to the GSC\n",
    "SSC = PATH_TO_CALBC_DISO # path to the SSC\n",
    "\n",
    "harmonize_ssc_gsc(GSC, SSC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract disjunction of annotated entity sets\n",
    "\n",
    "_Motivation_: Given a single SSC, and one or more GSC, we want to return the disjunction between annotated entities of the SSC, and all GSC (_which entities are present and annotated in the SSC, and present but not annotated in one more of the GSC_). \n",
    "\n",
    "_To use_: pass paths of corpus to `disjoint_entities(GSC, list_of_SSC)`. Returns disjunction of entity annotation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Example usage_: get disjoint annoations between SSC CALBC corpus and all corresponding GSC. Returns set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disjoint_annotations = disjoint_annotations(SSC, GSC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print each of these disjoint annotations, seperated by newline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disjoint_annotations = sorted(list(set([ann.lower().strip() for ann in disjoint_annotations])))\n",
    "print('\\n'.join(disjoint_annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove these disjoint entities from a SSC (note, requires that they are placed in a blacklist `.txt` file, with each entity appearing on its own line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blacklist = CALBC_CHED_BLACKLIST\n",
    "rm_disjoint_annotations(PATH_TO_CALBC_CHED, blacklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform an error analysis by looking at the sets of FP, FN, and TP of a model. In our case we will want to compare performance before and after transfer learning. We make the following assumptions: \n",
    "\n",
    "- predictions on the corpus from the baseline model are stored at: `path/to/corpus/deploy_test_baseline`\n",
    "- predictions on the corpus from the transfer learning model are stored at: `path/to/corpus/deploy_test_tl`\n",
    "- gold standard labels for the corpus are stored at: `path/to/corpus/test`\n",
    "\n",
    "Here is a simple example for printing the number of FNs, FPs and TPs for the baseline and transfer learning methods (along with the intersection of these sets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# example\n",
    "corpus_dir = PATH_TO_S800\n",
    "\n",
    "path_to_pred_baseline = os.path.join(corpus_dir, 'deploy_test_baseline')\n",
    "path_to_pred_tl = os.path.join(corpus_dir, 'deploy_test_tl')\n",
    "path_to_gold = os.path.join(corpus_dir, 'test')\n",
    "\n",
    "print_corpus_eval(path_to_pred_baseline, path_to_pred_tl, path_to_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a more complicated use case. We accumulate the FNs, FPs, and TPs for all corpora of a given entity type for both the baseline and transfer learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to set this variable\n",
    "path_to_corpora = PATH_TO_PRGE_CORPORA\n",
    "\n",
    "# accumulators\n",
    "FN_baseline_acc, FP_baseline_acc, TP_baseline_acc = set(), set(), set()\n",
    "FN_tl_acc, FP_tl_acc, TP_tl_acc = set(), set(), set()\n",
    "\n",
    "for corpus in path_to_corpora:\n",
    "    # get paths to baseline, tl predictions and gold labels\n",
    "    path_to_pred_baseline = os.path.join(corpus, 'deploy_test_baseline')\n",
    "    path_to_pred_tl = os.path.join(corpus, 'deploy_test_tl')\n",
    "    path_to_gold = os.path.join(corpus, 'test')\n",
    "    \n",
    "    # get sets of FN, FP, and TP for baseline and transfer learning methods\n",
    "    FN_baseline, FP_baseline, TP_baseline = get_FN_FP_TP_single_corpus(path_to_pred_baseline, path_to_gold)\n",
    "    FN_tl, FP_tl, TP_tl = get_FN_FP_TP_single_corpus(path_to_pred_tl, path_to_gold)\n",
    "    \n",
    "    # add corpus name to each annotation, to prevent loss of identical annotations across corpora\n",
    "    FN_baseline = set([corpus + x for x in FN_baseline])\n",
    "    FP_baseline = set([corpus + x for x in FP_baseline])\n",
    "    TP_baseline = set([corpus + x for x in TP_baseline])\n",
    "    \n",
    "    FN_tl = set([corpus + x for x in FN_tl])\n",
    "    FP_tl = set([corpus + x for x in FP_tl])\n",
    "    TP_tl = set([corpus + x for x in TP_tl])\n",
    "    \n",
    "    # accumulate FNs, FPs and TPs across corpora\n",
    "    FN_baseline_acc = FN_baseline_acc | FN_baseline\n",
    "    FP_baseline_acc = FP_baseline_acc | FP_baseline\n",
    "    TP_baseline_acc = TP_baseline_acc | TP_baseline\n",
    "    \n",
    "    FN_tl_acc = FN_tl_acc | FN_tl\n",
    "    FP_tl_acc = FP_tl_acc | FP_tl\n",
    "    TP_tl_acc = TP_tl_acc | TP_tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can look for patterns. First look at the average length of elements in each set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('BASELINE\\n' + '-'*50)\n",
    "print('FNs \\n\\tCount: {}\\n\\tAvg length: {}'.format(len(FN_baseline_acc), \n",
    "                                                   average_len_of_iterable([x.split('\\t')[1] for x in FN_baseline_acc])))\n",
    "print('FPs \\n\\tCount: {}\\n\\tAvg length: {}'.format(len(FP_baseline_acc), \n",
    "                                                   average_len_of_iterable([x.split('\\t')[1] for x in FP_baseline_acc])))\n",
    "print('TPs \\n\\tCount: {}\\n\\tAvg length: {}'.format(len(TP_baseline_acc), \n",
    "                                                   average_len_of_iterable([x.split('\\t')[1] for x in TP_baseline_acc])))\n",
    "print()\n",
    "\n",
    "print('TRANSFER LEARNING\\n' + '-'*50)\n",
    "print('FNs \\n\\tCount: {}\\n\\tAvg length: {}'.format(len(FN_tl_acc), \n",
    "                                                   average_len_of_iterable([x.split('\\t')[1] for x in FN_tl_acc])))\n",
    "print('FPs \\n\\tCount: {}\\n\\tAvg length: {}'.format(len(FP_tl_acc), \n",
    "                                                   average_len_of_iterable([x.split('\\t')[1] for x in FP_tl_acc])))\n",
    "print('TPs \\n\\tCount: {}\\n\\tAvg length: {}'.format(len(TP_tl_acc), \n",
    "                                                   average_len_of_iterable([x.split('\\t')[1] for x in TP_tl_acc])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then at the intersection of sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "intersection = get_top_n_intersection(FN_baseline_acc, FN_tl_acc)\n",
    "\n",
    "print('FN\\n' + '-'*50)\n",
    "pp.pprint(get_top_n_intersection(FN_baseline_acc, FN_tl_acc))\n",
    "print('FP\\n' + '-'*50)\n",
    "pp.pprint(get_top_n_intersection(FP_baseline_acc, FP_tl_acc))\n",
    "print('TP\\n' + '-'*50)\n",
    "pp.pprint(get_top_n_intersection(TP_baseline_acc, TP_tl_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the relative complements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "intersection = get_top_n_intersection(FN_baseline_acc, FN_tl_acc)\n",
    "\n",
    "\n",
    "fn_b_minus_tl, fn_tl_minus_bl = get_top_n_difference(FN_baseline_acc, FN_tl_acc)\n",
    "fp_b_minus_tl, fp_tl_minus_bl = get_top_n_difference(FP_baseline_acc, FP_tl_acc)\n",
    "tp_b_minus_tl, tp_tl_minus_bl = get_top_n_difference(TP_baseline_acc, TP_tl_acc)\n",
    "\n",
    "print('Baseline \\ Transfer learning: FN\\n' + '-'*50)\n",
    "pp.pprint(fn_b_minus_tl)\n",
    "print()\n",
    "print('Baseline \\ Transfer learning: FP\\n' + '-'*50)\n",
    "pp.pprint(fp_b_minus_tl)\n",
    "print()\n",
    "print('Baseline \\ Transfer learning: TP\\n' + '-'*50)\n",
    "pp.pprint(tp_b_minus_tl)\n",
    "print()\n",
    "\n",
    "print('Transfer learning \\ Baseline: FN\\n' + '-'*50)\n",
    "pp.pprint(fn_tl_minus_bl)\n",
    "print()\n",
    "print('Transfer learning \\ Baseline: FP\\n' + '-'*50)\n",
    "pp.pprint(fp_tl_minus_bl)\n",
    "\n",
    "print()\n",
    "print('Transfer learning \\ Baseline: TP\\n' + '-'*50)\n",
    "pp.pprint(tp_tl_minus_bl)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
